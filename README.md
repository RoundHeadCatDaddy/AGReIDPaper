# üòé Awesome Aerial-Ground Person Re-Identification

Aerial-Ground Person Re-Identification aims to match pedestrians across drone-captured aerial and ground camera views, facing challenges from viewpoint discrepancies, resolution variations, lighting conditions, and background interference. Critical for smart surveillance, traffic management, and emergency response, it focuses on deep learning models (e.g., cross-view feature alignment networks, self-supervised strategies) to improve cross-domain accuracy and robustness, advancing vision systems in real-world applications.
## üìñ Table of Contents
- [üåü Spotlight: Our Contributions](#-spotlight-our-contributions)
## üåü Spotlight: Our Contributions

Below are selected works from our research group, focusing on advanced Cross-view Alignment.
- **[TIP 2025] SD-ReID: View-aware Stable Diffusion for Aerial-Ground Person Re-Identification** *[Paper]([https://arxiv.org/abs/2504.09549])*
- **[TIFS 2025] LATex: Leveraging Attribute-based Text Knowledge for Aerial-Ground Person Re-Identification** *[Paper]([https://arxiv.org/abs/2503.23722])*
- 
## üìù Papers & Methods
Image-based Aerial-Ground Person Re-Identification| Conference / Journal | Title | Resources |
|:---|:---|:---|
| **Neurips 2025** | GSAlign: Geometric and Semantic Alignment Network for Aerial-Ground Person Re-Identification | [Paper](https://openreview.net/attachment?id=bxELEjg3VE&name=pdf) [Code](https://github.com/stone96123/GSAlign?tab=readme-ov-file) |
| **ICCV 2025** | Bridging the Sky and Ground: Towards View-Invariant Feature Learning for Aerial-Ground Person Re-Identification | [Paper](https://openaccess.thecvf.com/content/ICCV2025/html/Khalid_Bridging_the_Sky_and_Ground_Towards_View-Invariant_Feature_Learning_for_ICCV_2025_paper.html) |
| **TIP 2025** | SD-ReID: View-aware Stable Diffusion for Aerial-Ground Person Re-Identification | [Paper](https://arxiv.org/abs/2504.09549)  |
| **TIFS 2025** | LATex: Leveraging Attribute-based Text Knowledge for Aerial-Ground Person Re-Identification | [Paper](https://arxiv.org/abs/2503.23722)  |
